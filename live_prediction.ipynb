{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde3132b-1ac4-432b-b9d1-68d5010fb2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All models loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 18:16:40.826 python[13087:108505] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image saved to 'captures/capture_20250707_181703.jpg'\n",
      "\n",
      "--- Running Predictions ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751905023.842898  108505 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1751905023.862661  109230 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751905023.874677  109228 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751905023.933831  109223 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN (MediaPipe) Prediction: che\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "CNN (Pixels) Prediction: fe\n",
      "-------------------------\n",
      "\n",
      "Image saved to 'captures/capture_20250707_181808.jpg'\n",
      "\n",
      "--- Running Predictions ---\n",
      "k-NN (MediaPipe) Prediction: qe\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "CNN (Pixels) Prediction: re\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751905088.494612  108505 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3\n",
      "W0000 00:00:1751905088.504534  110515 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751905088.509744  110519 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image saved to 'captures/capture_20250707_181813.jpg'\n",
      "\n",
      "--- Running Predictions ---\n",
      "k-NN (MediaPipe) Prediction: qe\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "CNN (Pixels) Prediction: re\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751905093.331838  108505 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3\n",
      "W0000 00:00:1751905093.345976  110675 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751905093.360808  110674 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image saved to 'captures/capture_20250707_181814.jpg'\n",
      "\n",
      "--- Running Predictions ---\n",
      "k-NN (MediaPipe) Prediction: qe\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "CNN (Pixels) Prediction: re\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751905094.365798  108505 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3\n",
      "W0000 00:00:1751905094.379224  110730 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751905094.393791  110728 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image saved to 'captures/capture_20250707_181815.jpg'\n",
      "\n",
      "--- Running Predictions ---\n",
      "k-NN (MediaPipe) Prediction: qe\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "CNN (Pixels) Prediction: re\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751905095.631109  108505 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3\n",
      "W0000 00:00:1751905095.647078  110781 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751905095.659760  110781 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Load All Models and Encoders ---\n",
    "try:\n",
    "    # Load k-NN assets\n",
    "    with open('knn_model.pkl', 'rb') as f:\n",
    "        knn_model = pickle.load(f)\n",
    "    with open('label_encoder_knn.pkl', 'rb') as f:\n",
    "        label_encoder_knn = pickle.load(f)\n",
    "    \n",
    "    # Load CNN assets\n",
    "    cnn_model = tf.keras.models.load_model('cnn_model.keras')\n",
    "    with open('label_encoder_cnn.pkl', 'rb') as f:\n",
    "        label_encoder_cnn = pickle.load(f)\n",
    "        \n",
    "    print(\"✅ All models loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find model files. Please train both models first.\")\n",
    "    exit()\n",
    "\n",
    "# --- Re-use Feature Extraction and Preprocessing Functions ---\n",
    "def extract_landmarks(image):\n",
    "    # (Same function from knn_model.ipynb)\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        landmarks = []\n",
    "        wrist_coords = hand_landmarks.landmark[0]\n",
    "        for lm in hand_landmarks.landmark:\n",
    "            landmarks.extend([lm.x - wrist_coords.x, lm.y - wrist_coords.y, lm.z - wrist_coords.z])\n",
    "        return np.array(landmarks)\n",
    "    return None\n",
    "\n",
    "def preprocess_for_cnn(image, image_size=(64, 64)):\n",
    "    # (Same preprocessing from cnn_model.ipynb)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    resized_image = cv2.resize(gray_image, image_size)\n",
    "    normalized_image = resized_image.astype(\"float32\") / 255.0\n",
    "    final_image = np.expand_dims(normalized_image, axis=[0, -1])\n",
    "    return final_image\n",
    "\n",
    "# --- Main Application ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "capture_folder = \"captures\"\n",
    "os.makedirs(capture_folder, exist_ok=True)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    cv2.imshow('Webcam - Press SPACE to Capture, Q to Quit', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord(' '): # Spacebar\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        capture_path = os.path.join(capture_folder, f\"capture_{timestamp}.jpg\")\n",
    "        cv2.imwrite(capture_path, frame)\n",
    "        print(f\"\\nImage saved to '{capture_path}'\")\n",
    "        \n",
    "        saved_image = cv2.imread(capture_path)\n",
    "        if saved_image is not None:\n",
    "            print(\"\\n--- Running Predictions ---\")\n",
    "            \n",
    "            # k-NN Prediction\n",
    "            landmarks = extract_landmarks(saved_image)\n",
    "            if landmarks is not None:\n",
    "                knn_pred_index = knn_model.predict([landmarks])[0]\n",
    "                knn_pred_label = label_encoder_knn.inverse_transform([knn_pred_index])[0]\n",
    "                print(f\"k-NN (MediaPipe) Prediction: {knn_pred_label}\")\n",
    "            else:\n",
    "                print(\"k-NN: Could not detect hand landmarks.\")\n",
    "\n",
    "            # CNN Prediction\n",
    "            cnn_image = preprocess_for_cnn(saved_image)\n",
    "            cnn_pred_probs = cnn_model.predict(cnn_image)\n",
    "            cnn_pred_index = np.argmax(cnn_pred_probs)\n",
    "            cnn_pred_label = label_encoder_cnn.inverse_transform([cnn_pred_index])[0]\n",
    "            print(f\"CNN (Pixels) Prediction: {cnn_pred_label}\")\n",
    "            \n",
    "            print(\"-------------------------\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
